#!/usr/bin/env python3# -*- coding: utf-8 -*-"""===============================================================================NeuroEng Voltage Transient Processor - Voltage Selector===============================================================================Author:     Ifra AnsariCreated:    2025-07-07Modified:   2025-10-15Version:    v1.2DESCRIPTION---------------------------âœ… PyCode2 for annotated plots: annotation on voltage plot    âœ… create code part 2    âœ… LOAD saved offset dataframe     âœ… VOLTAGE VALUES:         Create time list: (t1, t2, t3, t4, t5)            Define defalt time values:                 Time values (Âµs)   [-10, 0, 200, 204, 300]                Time values (ms)   [-0.01, 0, 0.200, 0.204, 0.300]            Prompt user to input time points (or press enter to use deafult)         Pull Voltage & Row #            Loop function                open dataframe                go through each df in the loaded dictionary                in the DF                    go to time column                     find the rows where the time values are closest to the time I give in a list                    make a new df dictionary, with the same key as in loaded df dictionary                        Example for each new dataframe:                            Time values   [t1, t2, t3, t4, t5]                            Rows          [r1, r2, r3, r4, r5]                            Voltage       [v1, v2, v3, v4, v5]                    select minimum value for v3 around the time t3.                        âœ… PLOT        set default time scale -0.1 to 0.7        Overlay plots for each TEK_offset, consisting of:            a. Time vs Voltage line plot - from loaded dictionary (as created in Code Part 1)            b. Time vs Voltage scatter plot - with 5 markers displayed on top of line plot    âœ… VOLTAGE SUMMARY DATA TABLE        make new data table with the following columns:            Key - for TEK...            Eipp (v1)            v2             Vc peak (v3)            Emc (v4)            E IPend (v5)            Vacc leading (v2=v1)            Î”V (v3-v1)            Î”Ep (v3-v2)            Vacc trailing (v4=v3)            âœ… ADDITONAL COLUMNS (add later):                ExperimentDate(YYYYMMDD)                WaferID(IF00xx)                DeviceID(IIAxx)                ElectrodeID                Current(uA)                PulseWidth(Âµs)                IPdelay(Âµs)                Frequency(Hz)           populate data table for each TEK with available & calculatable values.            âœ… EXPORT        save mastervoltage summary dictionary        save master voltage summary data table         save individual TEK line + scatter plots as png"""# =============================================================================# ðŸ“¦ IMPORT REQUIRED PACKAGES# =============================================================================print("ðŸŸ  ðŸ“¦ Importing Packages...")# --- System & Core Python ---import osimport sys                          # System exit and interpreter controlimport platform                     # Detect OS (Windows/macOS/Linux)import getpass                      # pkl_path_folderrent system usernameimport time                         # Delay for exits or debuggingfrom datetime import datetime       # Timestamp for saved filesimport json                         # Export metadataimport pickle                       # Save/load Python objects# --- GUI ---from tkinter import Tk, filedialog  # File picker# --- Math, Data ---import numpy as np                  # Numerical operationsimport pandas as pd                 # DataFrame handling# --- Plotting ---import matplotlibimport matplotlib.pyplot as pltfrom matplotlib import rcParams# =============================================================================# ðŸ› ï¸ GLOBAL CONFIGURATION# =============================================================================print("ðŸŸ  ðŸ› ï¸ Global Configuration...")# --------------------# Script Info# --------------------script_name = "20250805_PEDOT_VTplots_BatchOverlay_Final_Part2.py"script_version = "2025-08-05"df_system_info = {    "system": platform.system(),    "release": platform.release(),    "python_version": platform.python_version(),    "user": getpass.getuser()}# --------------------# ðŸŽ¨ Global Plot Style (matplotlib.rcParams)# --------------------rcParams.update({    # --- ðŸ–‹ï¸ Font & Layout ---    "font.family": "Arial",              # Global font family   # e.g., "Arial", "Times New Roman", "Helvetica", "DejaVu Sans"    "font.size": 10,                     # Base font size       # e.g., 8, 10, 12    "font.weight": "normal",             # Global font weight   # "normal", "bold", "light", "medium", "heavy"    "axes.labelsize": 12,                # Axis label size      # integer (e.g., 10, 12, 14)    "axes.labelweight": "normal",        # Axis label weight    # "normal", "bold"    "axes.titlesize": 14,                # Plot title size      # integer (e.g., 14, 16)    "axes.titleweight": "normal",        # Plot title weight    # "normal", "bold"    "axes.titlepad": 10,                 # Space between title and plot  # int/float (padding in points)    # --- ðŸ“ Axes Style ---    "axes.linewidth": 1,                 # Border thickness     # float (e.g., 0.8, 1.0, 1.5)    "axes.facecolor": "white",           # Plot background      # e.g., "white", "lightgray", "#f0f0f0"    "axes.grid": False,                  # Enable gridlines     # True or False    # --- ðŸ“Š Grid Style ---              # Applies if axes.grid = True    "grid.color": "#dddddd",             # Grid line color      # e.g., "#cccccc", "lightgray"    "grid.linestyle": "--",              # Grid line style      # "-", "--", ":", "-."    "grid.linewidth": 0.5,               # Grid line thickness  # float (e.g., 0.3, 0.5, 1.0)    # --- ðŸ“ Tick Style ---    "xtick.labelsize": 10,               # X tick font size     # int (e.g., 8â€“12)    "ytick.labelsize": 10,               # Y tick font size     # int    "xtick.major.width": 1,              # X tick thickness     # float    "ytick.major.width": 1,              # Y tick thickness     # float    "xtick.direction": "out",            # X tick direction     # "in", "out", "inout"    "ytick.direction": "out",            # Y tick direction     # "in", "out", "inout"    # --- ðŸ“ˆ Line Style ---    "lines.linewidth": 1,                # Default line width   # float (e.g., 1.0, 2.0)    # --- ðŸ–¼ï¸ Figure Layout ---    "figure.figsize": (7.2, 4),          # Default plot size    # tuple (width, height) in inches    "figure.autolayout": True,           # Auto-layout on save  # True = avoids clipping axis labels    # --- ðŸ’¾ Save Style ---    "savefig.dpi": 300,                  # Output resolution    # e.g., 100, 200, 300 (for high-res export)    # --- ðŸ—‚ï¸ Legend Style ---    "legend.title_fontsize": 10,         # Legend title font    # int    "legend.fontsize": 9,                # Legend text size     # int    "legend.loc": "best",                # Legend placement     # "best", "upper right", "lower left", etc.    "legend.frameon": False,             # Show legend box      # True or False    "legend.edgecolor": "gray",          # Legend box color     # ignored if frame is off    "legend.fancybox": True,             # Rounded box corners  # True or False    "legend.borderpad": 0.4,             # Space around legend  # float    # --- ðŸ”  Text Rendering ---    "text.usetex": False,                # Use LaTeX            # True (pretty, slow) or False (faster)})SAVE_FORMATS = ("png")# =============================================================================# ðŸ” COLUMN STANDARDIZATION â†’ canonical: Time (Âµs), Voltage (V), current (A)# =============================================================================# --------------------# ðŸ› ï¸ ðŸ“¦ Default Channel Map# --------------------# ---- Channel â†’ Meaning mapping (edit if CH1/CH2 are swapped) ----dict_TEK_CHANNEL_MAP = {    "time":    "TIME",    "voltage": "CH1",   # switch to "CH2" if voltage is on CH2    "current": "CH2",   # switch to "CH1" if current is on CH1}# Canonical column names (after standardization)xcol_t = "Time (Âµs)"ycol_v = "Voltage (V)"ycol_i = "Current (A)"# Axis labels (for plots)dict_AXIS_LABELS = {    "time":    "Time (Âµs)",    "voltage": "Voltage (V)",    "current": "Current (A)",}# Default Time Scale (for plots) in Âµsxmin_t_default = -100   # in Âµsxmax_t_default = 700    # in Âµs# Aliases weâ€™ll recognize across files_TIME_ALIASES_us = ["time_us","Time (us)", "Time_us", "T (us)"]_TIME_ALIASES_Âµs = ["time_Âµs","Time (Âµs)", "Time_Âµs", "T (Âµs)"]_TIME_ALIASES_ms = ["time_ms","Time (ms)", "Time_ms", "T (ms)"]_TIME_ALIASES_s  = ["time_s","Time (s)", "Time_s", "T (s)","TIME","Time"]_VOLT_ALIASES    = ["voltage_V","Voltage_V","Voltage (V)","Voltage","voltage","V","CH1"]_CURR_ALIASES    = ["Current","current","current_A","Current_A","Current (A)","I","CH2"]CANON_TIME_UNIT = "Âµs"CANON_TIME = "Time (Âµs)"CANON_VOLT = "Voltage (V)"CANON_CURR = "Current (A)"def _pick_first_present(df, names):    for n in names:        if n in df.columns:            return n    return Nonedef _coerce_numeric(series):    return pd.to_numeric(series, errors="coerce")def standardize_dataframe_to_Âµs(df_in: pd.DataFrame, channel_map: dict | None = None) -> pd.DataFrame:    """    Return a NEW DataFrame with canonical columns:      Time (Âµs), Voltage (V), Current (A)    - Detects and converts time from s/ms/Âµs â†’ Âµs    - Resolves Voltage/Current from explicit names or CH1/CH2 using channel_map    - Coerces to numeric, drops rows with missing canonical cols, sorts by time    """    df = df_in.copy()    # ---------- TIME ----------    time_col = (        _pick_first_present(df, _TIME_ALIASES_Âµs)        or _pick_first_present(df, _TIME_ALIASES_us)        or _pick_first_present(df, _TIME_ALIASES_ms)        or _pick_first_present(df, _TIME_ALIASES_s)    )    if time_col is None:        raise KeyError("No recognizable time column found for conversion to Âµs.")    t = _coerce_numeric(df[time_col])    if time_col in _TIME_ALIASES_Âµs:        t_Âµs = t    elif time_col in _TIME_ALIASES_ms:        t_Âµs = t * 1e3    else:  # seconds â†’ Âµs        t_Âµs = t * 1e6    # ---------- VOLTAGE ----------    v_col = _pick_first_present(df, _VOLT_ALIASES)    if v_col is None and channel_map:        # prioritize mapped names        mapped_v = channel_map.get("voltage", "CH1")        if mapped_v in df.columns:            v_col = mapped_v    if v_col is None:        raise KeyError("No recognizable voltage column (e.g., 'Voltage (V)', 'voltage_V', or mapped CH1/CH2).")    v = _coerce_numeric(df[v_col])    # ---------- CURRENT ----------    i_col = _pick_first_present(df, _CURR_ALIASES)    if i_col is None and channel_map:        mapped_i = channel_map.get("current", "CH2")        if mapped_i in df.columns:            i_col = mapped_i    # Current is optional in some workflows; only add if found    i = _coerce_numeric(df[i_col]) if i_col is not None else None    # ---------- Assemble canonical DF ----------    out = pd.DataFrame({CANON_TIME: t_Âµs, CANON_VOLT: v})    if i is not None:        out[CANON_CURR] = i    # Clean and sort    keep_cols = [CANON_TIME, CANON_VOLT] + ([CANON_CURR] if CANON_CURR in out.columns else [])    out = out.dropna(subset=keep_cols).sort_values(by=CANON_TIME).reset_index(drop=True)    return outdef standardize_dict_to_Âµs(dct: dict[str, pd.DataFrame], channel_map: dict | None = None) -> dict[str, pd.DataFrame]:    """Apply standardize_dataframe_to_Âµs to every DF in a dict."""    out = {}    for k, df in dct.items():        try:            out[k] = standardize_dataframe_to_Âµs(df, channel_map=channel_map)        except Exception as e:            print(f"âš ï¸ Skipping {k}: {e}")    return out# =============================================================================# ðŸ“ LOAD SAVED PKL DICTIONARY (.pkl)# =============================================================================# --------------------# ðŸ“ GUI FILE PICKER# --------------------print("ðŸŸ  ðŸ–¥ï¸ Opening File Picker")print("\nâ— ACTION REQUIRED â—")print("ðŸ‘‰ ðŸ“ Select one .pkl file")Tk().withdraw()pkl_path = filedialog.askopenfilename(    title="Select .pkl file",    filetypes=[("Pickle files", "*.pkl")])if not pkl_path:    print("ðŸš« No file selected. Exiting.")    print("_" * 80)    sys.exit()    #--------------------# ðŸ“ SELECTED PKL FOLDER#--------------------pkl_path_folder = os.path.dirname(pkl_path)pkl_path_name = os.path.basename(pkl_path_folder)print(f"\nâ†³ âœ… Selected .pkl File:    â†’ {os.path.basename(pkl_path)}")print(f"\nâ†³ ðŸ“‚ Selected Folder:        â†’ {pkl_path_folder}")# Determine existing export parent (â€¦/VT_Py_Outputs)folder_path_export_parent = (    pkl_path_folder    if os.path.basename(pkl_path_folder) == "VT_Py_Outputs"    else os.path.dirname(pkl_path_folder))#--------------------# ðŸ“ METADATA PARENT FOLDER from pkl_path#--------------------def get_parent_data_folder_from_pkl(pkl_path: str) -> str:    """    If pkl lives under .../VT_Py_Outputs/<anything>/..., return the directory    immediately above 'VT_Py_Outputs'. Otherwise, return the pkl's directory.    """    pkl_path_folder = os.path.dirname(pkl_path)    parts = pkl_path_folder.split(os.sep)    # Walk up until we find 'VT_Py_Outputs'    while parts:        if parts[-1] == "VT_Py_Outputs":            # parent of VT_Py_Outputs is the metadata parent            return os.sep.join(parts[:-1]) or os.sep        parts.pop()  # climb one level up    # Fallback: no VT_Py_Outputs in the path â†’ use the pkl's directory    return os.path.dirname(pkl_path)# Use itfolder_path_parent = get_parent_data_folder_from_pkl(pkl_path)print(f"\nâ†³ ðŸ“‚ Metadata Parent folder: â†’ {folder_path_parent}")# ---------------------------# ðŸ“¤ ðŸ“‚ CREATE OUTPUT FOLDERS# ---------------------------def create_dated_export_folder(folder_path_export_parent: str,                               child_tag: str = "VT_Py_Outputs_VoltageSelector"):    """    Create ONLY a timestamped subfolder inside an existing export parent folder    (which should be .../VT_Py_Outputs). Does NOT create/rename the parent.    Returns:        folder_path_export_child, timestamp_str    """    # Sanity check: ensure we're inside VT_Py_Outputs    if os.path.basename(folder_path_export_parent) != "VT_Py_Outputs":        raise ValueError(            f"folder_path_export_parent must be a 'VT_Py_Outputs' directory, got: {folder_path_export_parent}"        )    # Make sure the parent exists (no-op if already there)    os.makedirs(folder_path_export_parent, exist_ok=True)    # Timestamped child export folder    timestamp_str = datetime.now().strftime("%Y%m%d_%H%M")    folder_path_export_child = os.path.join(        folder_path_export_parent, f"{child_tag}_{timestamp_str}"    )        # Create the child export folder    os.makedirs(folder_path_export_child, exist_ok=True)    return folder_path_export_child, timestamp_str# -----------------------------------------------------------------------------# ðŸ“‚ Create export folders next to the selected .pkl (inside its directory)# -----------------------------------------------------------------------------# Create only the dated child under VT_Py_Outputsfolder_path_export_child, timestamp_str = create_dated_export_folder(folder_path_export_parent)print(f"\nâœ… Created Export Folders: "      f"\n   â†³ðŸ“‚{os.path.basename(folder_path_export_parent)}"      f"\n     â†³ðŸ“‚{os.path.basename(folder_path_export_child)}")# --------------------# ðŸ“¤ LOAD PICKLE# --------------------try:    with open(pkl_path, 'rb') as f:        dict_df_TEK_loaded = pickle.load(f)        # Normalize every DF in the loaded dict to canonical Âµs/V/A        dict_df_TEK_loaded = standardize_dict_to_Âµs(dict_df_TEK_loaded, channel_map=dict_TEK_CHANNEL_MAP)                if not dict_df_TEK_loaded:            print("ðŸš« No traces remain after standardization. Check your inputs/columns.")            sys.exit()    print(f"\nâœ… Loaded dictionary with {len(dict_df_TEK_loaded)} TEK traces:")                    for i, key in enumerate(dict_df_TEK_loaded.keys(), start=1):        print(f"   {i}. {key}")except Exception as e:    print(f"ðŸš« Error loading .pkl file: {e}")    sys.exit()# =============================================================================# ðŸš¸ USER-DEFINED TIME POINTS & VOLTAGE EXTRACTION WITH ROW INFO (v2)# =============================================================================# --------------------# ðŸ‘‰ ðŸ§­ USER INPUT: Custom time values (Âµs)# --------------------print("\nâ— ACTION REQUIRED â—")print(f"ðŸ‘‰ Enter 5 time points ({CANON_TIME_UNIT}) to extract voltage values.")# Default valuest_defaults_Âµs = [-25, 1, 198, 201, 292]print("ðŸ”¹ If...")print(f" âžŸ Phase Width              = 200 {CANON_TIME_UNIT}")print(f" âžŸ IPdelay                  = 100 {CANON_TIME_UNIT}")print(f" âžŸ Pulse Start (t0)         = 0  {CANON_TIME_UNIT}")print("ðŸ”¹ Then...")print(f" âžŸ t1 =  t0 - 25            = -25 {CANON_TIME_UNIT}")print(f" âžŸ t2 =  t0 + 4             = 4   {CANON_TIME_UNIT}")print(f" âžŸ t3 = (t0 + PW) - 4       = 196 {CANON_TIME_UNIT}")print(f" âžŸ t4 = (t0 + PW) + 4       = 204 {CANON_TIME_UNIT}")print(f" âžŸ t5 = (t0 + PW + IP)- 6   = 294 {CANON_TIME_UNIT}")print(f"\nðŸ‘‰ Press Enter for default: \n   {t_defaults_Âµs}({CANON_TIME_UNIT})")time_points_Âµs = []for i in range(5):    prompt = f"   âœï¸ t{i+1} [Press Enter for {t_defaults_Âµs[i]}]: ðŸ‘‰ "    try:        t_val = input(prompt).strip()        time_points_Âµs.append(float(t_val) if t_val else t_defaults_Âµs[i])    except ValueError:        print(f"ðŸš« Invalid input for t{i+1}. Using default: {t_defaults_Âµs[i]}")        time_points_Âµs.append(t_defaults_Âµs[i])print(f"   âœ… Time points ({CANON_TIME_UNIT}):\n", time_points_Âµs)# --------------------# ðŸš¸ Extract voltage & row values from each DataFrame# --------------------print("\nðŸŸ  Processing each trace to find closest voltage values at given time points...")dict_df_TEK_Vpoints = {}for key, df in dict_df_TEK_loaded.items():    try:        V_summary_rows = []        for t_target in time_points_Âµs:            # Find closest time index            idx_closest = (df[xcol_t] - t_target).abs().idxmin()            row_number = idx_closest + 1  # 1-based index for original CSV            row = df.loc[idx_closest]            V_summary_rows.append({                "Row #": row_number,                xcol_t: row[xcol_t],                ycol_v: row[ycol_v]            })        df_TEK_Vpoints = pd.DataFrame(V_summary_rows)        dict_df_TEK_Vpoints[key] = df_TEK_Vpoints        print(f"âœ… Extracted Voltage & Row # from: {key}")    except Exception as e:        print(f"ðŸš« Failed to process {key}: {e}")# ðŸ“‹ Show preview of one resultexample_key = list(dict_df_TEK_Vpoints.keys())[0]print("\nðŸ“‹ Example Summary for:", example_key)print(dict_df_TEK_Vpoints[example_key])# =============================================================================# ðŸ” IMPROVE v3: Replace with Min Voltage Near t3 Â± Î”# =============================================================================print("\nðŸ› ï¸ Updating v3 (time point 3) with local minimum voltage value...")delta_Âµs = 10  # Search Â±10 Âµs around t3for key, df in dict_df_TEK_loaded.items():    try:        t3 = time_points_Âµs[2]  # original t3        # Create mask for time window        mask = (df[xcol_t] >= t3 - delta_Âµs) & (df[xcol_t] <= t3 + delta_Âµs)        df_window = df[mask]        if not df_window.empty:            # Find row with minimum voltage            idx_min = df_window[ycol_v].idxmin()            row_number = idx_min + 1            row = df.loc[idx_min]            # Update t3 (index 2) in summary            dict_df_TEK_Vpoints[key].iloc[2] = {                "Row #": row_number,                xcol_t: row[xcol_t],                ycol_v: row[ycol_v]            }            print(f"âœ… Updated v3 for: {key}")        else:            print(f"âš ï¸ No data near t3={t3} Âµs in {key}. Skipping v3 update.")    except Exception as e:        print(f"ðŸš« Failed to update v3 for {key}: {e}")        # =============================================================================# ðŸ“ USER PROMPT: Time Scale for Plots# =============================================================================print("\nâ— ACTION REQUIRED â—")print(f"ðŸ‘‰ Choose x-axis Time ({CANON_TIME_UNIT}) limits for all plots")print(f"   ðŸ§  Press Enter for default {CANON_TIME_UNIT}: {xmin_t_default} to {xmax_t_default}")try:    tmin = input(f"   â±ï¸ xmin [Press Enter for {xmin_t_default} {CANON_TIME_UNIT}]: ðŸ‘‰ ").strip()    tmax = input(f"   â±ï¸ xmax [Press Enter for {xmax_t_default} {CANON_TIME_UNIT}]: ðŸ‘‰ ").strip()        xmin_t_default = float(tmin) if tmin else xmin_t_default    xmax_t_default = float(tmax) if tmax else xmax_t_defaultexcept ValueError:    print("âš ï¸ Invalid input. Using defaults.")    # =============================================================================# ðŸ“Š PLOT: Line + Scatter Overlay (One Figure per TEK File)# =============================================================================print("\nðŸ“Š Creating V plots per TEK file.")for key in dict_df_TEK_loaded:    try:        df = dict_df_TEK_loaded[key]        df_TEK_Vpoints = dict_df_TEK_Vpoints[key]        fig, ax = plt.subplots()        # --- Plot line trace ---        ax.plot(df[xcol_t], df[ycol_v], label=f"{key}", linewidth=1.5)        # --- Overlay 5 scatter points ---        ax.scatter(df_TEK_Vpoints[xcol_t], df_TEK_Vpoints[ycol_v],                   color='red', s=5, label="Selected Points", zorder=5)        # --- Format & Style ---        ax.set_title(f"{key} â€” Time vs Voltage", fontweight='bold')        ax.set_xlabel(xcol_t, fontweight='bold')        ax.set_ylabel(ycol_v, fontweight='bold')        ax.set_xlim(xmin_t_default, xmax_t_default)        ax.set_facecolor("white")        ax.grid(True, linestyle='--', alpha=0.3)        ax.legend(loc="best")        plt.tight_layout()        # ---- SAVE PLOT FILES (png) ----        file_base = f"PyVS_{key}_SelectedVals"        for ext in SAVE_FORMATS:            out_fig = os.path.join(folder_path_export_child, f"{file_base}.{ext}")            fig.savefig(out_fig, dpi=rcParams.get("savefig.dpi", 300))            print(f"âœ… ðŸ–¼ï¸ Saved plot: {os.path.basename(out_fig)}")        plt.show()        plt.close(fig)  # free memory        print(f"âœ… Plotted: {key}")    except Exception as e:        print(f"ðŸš« Could not plot {key}: {e}")# =============================================================================# ðŸ§¾ SUMMARY TABLE with Folder Auto-Detection + User Prompts# =============================================================================import os, reimport pandas as pddef parse_folder_metadata(folder_name: str):    """    Expect patterns like:      20250506_IF0013_IIA41_PEDOT_VT_1Billion      20250505_IF0013_IIA41_PEDOT_VT_VariableQ    Returns dict with keys: ExpDate, WaferID, DeviceID, Material, TestType1, TestType2    Any that can't be parsed become "" and will be prompted later.    """    out = {"ExpDate":"", "WaferID":"", "DeviceID":"", "Material":"", "TestType1":"", "TestType2":""}    # Split on underscores    parts = folder_name.strip().split("_")    # Date YYYYMMDD    if parts and re.fullmatch(r"\d{8}", parts[0] or ""):        out["ExpDate"] = parts[0]    # WaferID IFxxxx (e.g., IF0013)    for p in parts:        if re.fullmatch(r"IF\d{4,}", p):            out["WaferID"] = p            break    # DeviceID IIAxx (e.g., IIA41)    for p in parts:        if re.fullmatch(r"IIA\d{2,}", p):            out["DeviceID"] = p            break    # Material (take the next non-matched token after DeviceID if present)    # Heuristic: find index of DeviceID and look at the next token    try:        idx_dev = parts.index(out["DeviceID"]) if out["DeviceID"] in parts else -1    except ValueError:        idx_dev = -1    if idx_dev >= 0 and idx_dev + 1 < len(parts):        cand = parts[idx_dev + 1]        # Skip if it looks like IF/IIA/date again        if not re.fullmatch(r"(IF\d+|IIA\d+|\d{8})", cand):            out["Material"] = cand    # TestType1 and TestType2: take the next two tokens after Material    try:        idx_mat = parts.index(out["Material"]) if out["Material"] in parts else -1    except ValueError:        idx_mat = -1    if idx_mat >= 0:        if idx_mat + 1 < len(parts):            out["TestType1"] = parts[idx_mat + 1]        if idx_mat + 2 < len(parts):            out["TestType2"] = parts[idx_mat + 2]    return outdef prompt_or_keep(label, current_val=""):    """    Ask user to Input value (or press Enter to leave blank).    If current_val provided, show it as [detected]; user can press Enter to keep it,    or type to overwrite; typing only Enter with empty current_val leaves blank.    """    if current_val:        user = input(f"{label} [{current_val}] (Press Enter to keep / type to change): ").strip()        return current_val if user == "" else user    else:        user = input(f"{label}: ").strip()        return user  # may be ""# -------------------- Detect from folder name --------------------# Use your existing folder_path_parent (from your earlier code)folder_name_parent = os.path.basename(folder_path_parent)auto_meta = parse_folder_metadata(folder_name_parent)print("\nðŸŸ  Auto-detected from folder name:", folder_name_parent)for k, v in auto_meta.items():    print(f"   - {k}: {v if v else '(not detected)'}")print("\nðŸ”§ If auto-detection failed or you want to change a value, type a new one.")print("   Otherwise, press Enter to keep (or leave blank if none).")# Confirm/overwrite auto-detected fields (allow blank)ExpDate   = prompt_or_keep("ExpDate (YYYYMMDD)", auto_meta.get("ExpDate", ""))WaferID   = prompt_or_keep("WaferID (e.g., IF0013)", auto_meta.get("WaferID", ""))DeviceID  = prompt_or_keep("DeviceID (e.g., IIA41)", auto_meta.get("DeviceID", ""))Material  = prompt_or_keep("Material", auto_meta.get("Material", ""))TestType1 = prompt_or_keep("TestType1", auto_meta.get("TestType1", ""))TestType2 = prompt_or_keep("TestType2", auto_meta.get("TestType2", ""))ElectrodeID   = prompt_or_keep("ElectrodeID")# -------------------- Always ask for these (allow blank) --------------------print("\nðŸŸ  Enter run-specific inputs (Press Enter to leave blank cell):")Current_ÂµA    = prompt_or_keep("Current_ÂµA")PulseWidth_Âµs = prompt_or_keep("PulseWidth_Âµs")IPdelay_Âµs    = prompt_or_keep("IPdelay_Âµs")Frequency_Hz  = prompt_or_keep("Frequency_Hz")# -------------------- Build the summary table --------------------Summary_Vcalc = []for key, df in dict_df_TEK_Vpoints.items():    # Safely fetch first 5 points    def get_v(i):        try:            return df.iloc[i]["Voltage (V)"]        except Exception:            return None  # will show as NaN in DataFrame    v1 = get_v(0); v2 = get_v(1); v3 = get_v(2); v4 = get_v(3); v5 = get_v(4)    row = {        # ðŸ”¹ File + Voltage metrics        "File": key,                # ðŸ”¹ Folder metadata (confirmed/edited)        "ExpDate": ExpDate,        "WaferID": WaferID,        "DeviceID": DeviceID,        "Material": Material,        "TestType1": TestType1,        "TestType2": TestType2,        # ðŸ”¹ User-entered run fields        "ElectrodeID": ElectrodeID,        "Current_ÂµA": Current_ÂµA,        "PulseWidth_Âµs": PulseWidth_Âµs,        "IPdelay_Âµs": IPdelay_Âµs,        "Frequency_Hz": Frequency_Hz,        # ðŸ”¹ Voltage metrics        "Eipp (v1)": v1,        "v2": v2,        "Vc peak (v3)": v3,        "Emc (v4)": v4,        "E IPend (v5)": v5,        "Vacc leading (v2=v1)": v1,        "Î”V (v3-v1)": (None if (v3 is None or v1 is None) else (v3 - v1)),        "Î”Ep (v3-v2)": (None if (v3 is None or v2 is None) else (v3 - v2)),        "Vacc trailing (v4=v3)": v3,    }    Summary_Vcalc.append(row)df_TEKall_Vcalc = pd.DataFrame(Summary_Vcalc)col_order = [    "File",    "ExpDate",    "WaferID",    "DeviceID",    "Material",    "TestType1",    "TestType2",    "ElectrodeID",    "Current_uA",    "PulseWidth_us",    "IPdelay_us",    "Frequency_Hz",    "Eipp (v1)",    "v2",    "Vc peak (v3)",    "Emc (v4)",    "E IPend (v5)",    "Vacc leading (v2=v1)",    "Î”V (v3-v1)",    "Î”Ep (v3-v2)",    "Vacc trailing (v4=v3)"]df_TEKall_Vcalc = df_TEKall_Vcalc.reindex(columns=col_order)df_TEKall_Vcalc = df_TEKall_Vcalc.fillna("")print("\nâœ…ðŸ“‹ Voltage Summary Table (first 5 rows):")print(df_TEKall_Vcalc.head())# =============================================================================# ðŸ“¤ EXPORT# =============================================================================try:    # 1) Export the summary table as UPPERCASE .CSV (Excel-friendly)    csv_name = "PyVS_Summary_CalculatedVals.CSV"    csv_path = os.path.join(folder_path_export_child, csv_name)    df_TEKall_Vcalc.to_csv(csv_path, index=False)    print(f"âœ… ðŸ’¾ Saved .csv: {csv_name}")    # 2) Export the per-file V-points dictionary as .pkl    pkl_name = "PyVS_Dictionary_AllDataFiles_SelectedVals.pkl"    pkl_out_path = os.path.join(folder_path_export_child, pkl_name)    with open(pkl_out_path, "wb") as f:        pickle.dump(dict_df_TEK_Vpoints, f)    print(f"âœ… ðŸ“š Saved .pkl: {pkl_name}")    # 3) (Optional) quick TXT manifest    txt_name = "PyVS_Summary.txt"    txt_path = os.path.join(folder_path_export_child, txt_name)    with open(txt_path, "w") as f:        f.write("Voltage Selector Export Manifest\n")        f.write("================================\n")        f.write(f"Timestamp:      {timestamp_str}\n")        f.write(f"Script:         {script_name} (v{script_version})\n")        f.write(f"User/System:    {df_system_info['user']} | "                f"{df_system_info['system']} {df_system_info['release']} | "                f"Python {df_system_info['python_version']}\n\n")        f.write(f"Input Folder:\n{pkl_path}\n\n")        f.write(f"Output Folder:\n{folder_path_export_child}\n\n")        f.write("Saved:\n")        f.write(f"  â€¢ {csv_name}\n")        f.write(f"  â€¢ {pkl_name}\n")        # list plots saved        f.write("  â€¢ Plots (*.png) per TEK key\n")    print(f"âœ… ðŸ—’ï¸ Saved .txt: {txt_name}")except Exception as e:    print(f"ðŸš« Export error: {e}")# %%# =============================================================================# ðŸ“Œ ðŸž To Do: NEXT# =============================================================================    # ðŸŸ  PyCode3 for final plots    # load dictionary from PyCode2    # make final plots